{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794f788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the ttolkit and the full Porter Stemmer Library\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9a2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9ac1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =['run','runner','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466d4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "runner-->runner\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d940c3",
   "metadata": {},
   "source": [
    "# runner is treated as noun therefore it is not stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72b999",
   "metadata": {},
   "source": [
    "QUESTIONS INTERVIEW \n",
    "\n",
    "WHATT ARE STAMEERS\n",
    "TYPES OF Stemmers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce16654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00cf4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "#words ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8416775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "runner-->runner\n",
      "running-->run\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "      print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a927d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5773202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-->i\n",
      "am-->am\n",
      "meeting-->meet\n",
      "him-->him\n",
      "tommorow-->tommorow\n",
      "at-->at\n",
      "the-->the\n",
      "meeting-->meet\n"
     ]
    }
   ],
   "source": [
    "phrase ='I am meeting him tommorow at the meeting'\n",
    "for word in phrase.split():\n",
    "    print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa1e5d",
   "metadata": {},
   "source": [
    "Lemmatizandtion looks beyond the word reduction, it is going to check the context --- Interviwer\n",
    "----------------<blue What is the diference between stemming and lemmatization >?-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a174d",
   "metadata": {},
   "source": [
    "Lemmatization in contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a morphological analysis to words. The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'. Further, the lemma of 'meeting' might be 'meet' or 'meeting' depending on its use in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6f79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21db81b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runnner \t NOUN \t 8100916699613223604 \t runnner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "i \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am a runnner running in a race because i love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b079f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}}{token.pos_:{6}}{token.lemma:<{22}}{token.lemma_:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc61cd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I           PRON  4690420944186131903             I\n",
      "saw         VERB  11925638236994514241          see\n",
      "eighteen    NUM   9609336664675087640      eighteen\n",
      "mice        NOUN  1384165645700560590         mouse\n",
      "today       NOUN  11042482332948150395        today\n",
      "!           PUNCT 17494803046312582752            !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u'I saw eighteen mice today!')\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3224a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I           PRON  4690420944186131903             I\n",
      "am          AUX   10382539506755952630           be\n",
      "meeting     VERB  6880656908171229526          meet\n",
      "him         PRON  1655312771067108281            he\n",
      "tommorrow   VERB  15839087253969881949    tommorrow\n",
      "at          ADP   11667289587015813222           at\n",
      "the         DET   7425985699627899538           the\n",
      "meeting     NOUN  14798207169164081740      meeting\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'I am meeting him tommorrow at the meeting')\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40bb62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That        PRON  4380130941430378203          that\n",
      "'s          AUX   10382539506755952630           be\n",
      "an          DET   15099054000809333061           an\n",
      "enormous    ADJ   17917224542039855524     enormous\n",
      "automobile  NOUN  7211811266693931283    automobile\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"That's an enormous automobile\")\n",
    "show_lemmas(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a07717",
   "metadata": {},
   "source": [
    "lemmazation doesnt make word to their synonims"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45c85e19",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7197df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4e81010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hence', 'along', 'really', 'neither', 'by', 'on', 'whereby', 'that', 'afterwards', 'fifty', 'thereby', 'top', 'where', 'during', 'to', 'few', 'somehow', 'various', 'everywhere', 'twenty', 'whereafter', 'other', 'a', 'ten', 'than', 'may', 'take', 'i', 'thru', 'further', 'another', 'last', 'none', 'or', 'nowhere', 'who', 'your', '‘s', '’d', 'cannot', 'eleven', 'say', 'were', 'four', 'not', 'there', 'whose', 'them', 'alone', 'least', 'call', 'therefore', 'move', \"'ve\", 'you', 'except', 'very', 'also', 'seeming', 'through', 'being', 'put', 'anyway', 'enough', 'before', \"'re\", 'thus', 'using', 'my', 'doing', 'what', 'does', 'for', 'formerly', 'serious', 'back', 'around', 'thereafter', 'as', 'is', 'ourselves', '‘d', 'next', 'already', 'whatever', 'always', 'quite', 'are', 'less', 'seem', 'due', 'whereas', 'hers', 'together', 'while', 'ca', '‘ll', 'bottom', 'amongst', 'often', 'many', 'but', 'and', '’m', 'five', '’ve', 'out', 'we', 'nine', 'via', \"n't\", 'either', 'others', 'whence', 'everyone', 'still', 'here', 'though', 'namely', 'onto', 'full', \"'ll\", 'in', '’s', 'he', 'hereafter', 'toward', 'amount', '‘m', 'any', 'twelve', 'could', 'against', 'beyond', 'sometimes', 'former', 'themselves', 'myself', 'do', 'therein', 'nobody', 'same', 'these', 'was', 'down', 'us', 'thence', 'noone', 'n’t', 'moreover', 'whoever', 'thereupon', '‘ve', 'one', \"'d\", 'became', 'an', 'make', 'mostly', 'anyone', 'see', 'been', 'unless', 'rather', 'part', 'meanwhile', 'its', 'can', 'first', 'which', 'front', 'his', 'much', 'two', 'might', 'some', 'with', 'me', 'forty', 'per', 'the', 'after', 'wherein', 'just', 'until', 'otherwise', 'please', 'regarding', 'else', 'n‘t', 'nevertheless', 'she', 'had', 'hereupon', 'even', 'why', 'done', 'well', 'if', 'anything', 'it', 'empty', 'at', 'own', 're', 'be', 'will', 'how', 'would', 'when', 'from', 'over', 'more', 'made', 'third', 'perhaps', 'hundred', '‘re', 'give', 'whom', 'never', 'herein', 'whole', 'him', 'become', 'mine', 'too', 'itself', 'her', 'under', 'above', 'whereupon', 'hereby', 'three', 'beforehand', 'behind', 'anywhere', 'latterly', 'besides', 'yet', 'nor', 'keep', 'something', '’re', 'whether', 'between', 'into', \"'s\", 'indeed', 'ever', 'their', 'anyhow', 'name', 'within', 'since', 'eight', 'go', 'has', 'again', 'every', 'wherever', 'of', 'nothing', 'below', 'now', 'because', 'becoming', 'sixty', 'yourselves', 'those', 'beside', 'yours', 'then', 'among', 'each', 'several', 'towards', 'all', 'am', 'ours', 'they', 'must', 'most', 'everything', 'sometime', \"'m\", 'someone', 'such', 'almost', 'so', 'throughout', 'show', 'this', 'about', 'seemed', 'used', 'our', 'off', 'becomes', 'six', 'should', 'both', 'did', 'himself', 'side', 'somewhere', 'only', 'fifteen', 'although', 'however', 'seems', 'have', 'upon', 'without', 'once', '’ll', 'latter', 'whenever', 'whither', 'elsewhere', 'yourself', 'get', 'across', 'no', 'up', 'herself'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79464b65",
   "metadata": {},
   "source": [
    "#  to see if a word is stop word or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "402ce49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d0463e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a81545",
   "metadata": {},
   "source": [
    "# To add a stop word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64d9bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the word\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a824db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f50706e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d76024",
   "metadata": {},
   "source": [
    "# To remove a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055f4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7d072fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6298024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05fc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
